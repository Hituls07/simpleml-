{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maintaning all the libraries \n",
    "\n",
    "import os \n",
    "import datetime\n",
    "import tarfile\n",
    "from six.moves import urllib \n",
    "import time\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit, cross_val_score , cross_val_predict, GridSearchCV\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor \n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists(os.path.join('.', 'DataUniverse')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_root = 'https://raw.githubusercontent.com/ageron/handson-ml/master/datasets/housing/housing.tgz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data_url (URL , name_dataset = 'housing_data'):\n",
    "    end_location = os.path.join('.', 'DataUniverse', name_dataset)\n",
    "    if not os.path.exists(end_location): \n",
    "        os.makedirs(end_location)\n",
    "    tgz_location = os.path.join(end_location, name_dataset + '.tgz')\n",
    "    urllib.request.urlretrieve(URL, tgz_location)\n",
    "    data_file = tarfile.open(tgz_location)\n",
    "    data_file.extractall(path = end_location) \n",
    "    data_file.close() \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_df = pd.read_csv('/Users/hitulshah/DataUniverse/housing_data/housing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_split(df , target_column, TEST_SIZE = 0.3):\n",
    "    split = StratifiedShuffleSplit(n_splits = 1, test_size= TEST_SIZE)\n",
    "    data = df.copy()\n",
    "    data['strat_var'] = np.ceil(data[target_column] / 100000)\n",
    "    for train_index, test_index in split.split(data,data['strat_var']):\n",
    "        data_train  = data.iloc[train_index].drop(columns= ['strat_var']) \n",
    "        data_test = data.iloc[test_index].drop(columns = ['strat_var']) \n",
    "    del data\n",
    "    print('Training Data Size{}'.format(data_train.shape))\n",
    "    print('Testing data Size{}'.format(data_test.shape))\n",
    "    return data_train.drop(columns = target_column), data_test.drop(columns = target_column), data_train[target_column], data_test[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Size(14448, 10)\n",
      "Testing data Size(6192, 10)\n"
     ]
    }
   ],
   "source": [
    "target = 'median_house_value'\n",
    "housing_feat_train, housing_feat_test, housing_train_target, housing_test_taget = stratified_split(housing_df, target_column= target) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColumnSelector(BaseEstimator,TransformerMixin): \n",
    "\n",
    "    '''\n",
    "    This substract class is designed to return data with inputed dcolumns\n",
    "    '''\n",
    "    def __init__(self, features_ = None, numeric = True):\n",
    "        self.features_ = features_\n",
    "        \n",
    "    def fit(self, x, Y = None): \n",
    "        return self\n",
    "    \n",
    "    def transform(self, x, Y = None): \n",
    "        return x[self.features_]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline= FeatureUnion([\n",
    "                            ('num_pipeline',num_pipe),\n",
    "                            ('cat_pipeline', cat_pipe)\n",
    "                            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(numeric_variables, cat_variables):\n",
    "    \n",
    "    num_pipe = Pipeline([\n",
    "                        ('selector', ColumnSelector(num_var)), \n",
    "                        ('imputor', SimpleImputer(strategy= 'median')),\n",
    "                        ('scaling', StandardScaler())\n",
    "                ]);\n",
    "    \n",
    "    cat_pipe = Pipeline([\n",
    "                    ('selector', ColumnSelector(cat_var)), \n",
    "                    ('imputor_cat', SimpleImputer(strategy= 'most_frequent')),\n",
    "                    ('encoder', OrdinalEncoder()), \n",
    "                    ('onehot', OneHotEncoder(categories= 'auto',sparse=False))\n",
    "                    ]);\n",
    "    \n",
    "    full_pipeline= FeatureUnion([\n",
    "                            ('num_pipeline',num_pipe),\n",
    "                            ('cat_pipeline', cat_pipe)\n",
    "                            ]);\n",
    "\n",
    "\n",
    "    return full_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_var = ['longitude','latitude','housing_median_age','total_rooms','total_bedrooms'\n",
    "           ,'population','households','median_income']\n",
    "cat_var = ['ocean_proximity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = Preprocessing(num_var , cat_var)\n",
    "housing_feat_transf_train = full_pipeline.fit_transform(housing_feat_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_reg = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "paras = {'n_estimators': [10,20,30], 'max_features': [5,7,10] , 'bootstrap' : [True, False]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(rf_reg,param_grid= paras , scoring = 'neg_mean_squared_error',cv= 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'n_estimators': [10, 20, 30], 'max_features': [5, 7, 10], 'bootstrap': [True, False]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(housing_feat_transf_train, housing_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False, 'max_features': 7, 'n_estimators': 30}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvres = grid.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(-2751776193.9308467,\n",
       "  {'bootstrap': False, 'max_features': 10, 'n_estimators': 10}),\n",
       " (-2695567274.639811,\n",
       "  {'bootstrap': False, 'max_features': 10, 'n_estimators': 20}),\n",
       " (-2691886490.8124814,\n",
       "  {'bootstrap': True, 'max_features': 10, 'n_estimators': 10}),\n",
       " (-2667979508.39847,\n",
       "  {'bootstrap': True, 'max_features': 5, 'n_estimators': 10}),\n",
       " (-2659645454.57189,\n",
       "  {'bootstrap': False, 'max_features': 5, 'n_estimators': 10}),\n",
       " (-2654673067.014958,\n",
       "  {'bootstrap': True, 'max_features': 7, 'n_estimators': 10}),\n",
       " (-2625792841.711316,\n",
       "  {'bootstrap': False, 'max_features': 7, 'n_estimators': 10}),\n",
       " (-2606775091.927631,\n",
       "  {'bootstrap': False, 'max_features': 10, 'n_estimators': 30}),\n",
       " (-2530155879.8460236,\n",
       "  {'bootstrap': True, 'max_features': 10, 'n_estimators': 20}),\n",
       " (-2514053100.091453,\n",
       "  {'bootstrap': True, 'max_features': 5, 'n_estimators': 20}),\n",
       " (-2506343467.2295127,\n",
       "  {'bootstrap': True, 'max_features': 7, 'n_estimators': 20}),\n",
       " (-2486614947.961313,\n",
       "  {'bootstrap': False, 'max_features': 7, 'n_estimators': 20}),\n",
       " (-2484185923.344276,\n",
       "  {'bootstrap': True, 'max_features': 5, 'n_estimators': 30}),\n",
       " (-2482805624.904271,\n",
       "  {'bootstrap': False, 'max_features': 5, 'n_estimators': 20}),\n",
       " (-2466646954.9856534,\n",
       "  {'bootstrap': True, 'max_features': 7, 'n_estimators': 30}),\n",
       " (-2445160363.05761,\n",
       "  {'bootstrap': False, 'max_features': 5, 'n_estimators': 30}),\n",
       " (-2441349074.691714,\n",
       "  {'bootstrap': True, 'max_features': 10, 'n_estimators': 30}),\n",
       " (-2431966032.592254,\n",
       "  {'bootstrap': False, 'max_features': 7, 'n_estimators': 30})]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(cvres['mean_test_score'], cvres['params']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'onehot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-171-e83d93ce65a4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0monehot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'onehot' is not defined"
     ]
    }
   ],
   "source": [
    "onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
